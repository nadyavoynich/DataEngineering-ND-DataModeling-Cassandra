{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/home\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "# print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‰ There are fewer rows in the new CSV file because the initial files contains empty rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Data Modeling with Apache Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The denormalized data, stored in 'event_datafile_new.csv', is presented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rokia TraorÃƒÂƒÃ‚Â©</td>\n",
       "      <td>Stefany</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>274.88608</td>\n",
       "      <td>free</td>\n",
       "      <td>Lubbock, TX</td>\n",
       "      <td>693</td>\n",
       "      <td>Zen</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camila</td>\n",
       "      <td>Tucker</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Garrison</td>\n",
       "      <td>230.81751</td>\n",
       "      <td>free</td>\n",
       "      <td>Oxnard-Thousand Oaks-Ventura, CA</td>\n",
       "      <td>555</td>\n",
       "      <td>Abrazame  (Version Acustica)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carl Thomas</td>\n",
       "      <td>Tucker</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Garrison</td>\n",
       "      <td>196.67546</td>\n",
       "      <td>free</td>\n",
       "      <td>Oxnard-Thousand Oaks-Ventura, CA</td>\n",
       "      <td>698</td>\n",
       "      <td>You Ain't Right (Album Version)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N.E.R.D.</td>\n",
       "      <td>James</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>242.99057</td>\n",
       "      <td>free</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>78</td>\n",
       "      <td>Provider (Remix Radio Edit)</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lil Jon / The East Side Boyz / DJ Flexx</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Lynch</td>\n",
       "      <td>285.30893</td>\n",
       "      <td>paid</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>589</td>\n",
       "      <td>Aww Skeet Skeet</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Enya</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>Lynch</td>\n",
       "      <td>175.85587</td>\n",
       "      <td>paid</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>589</td>\n",
       "      <td>The Sun In The Stream</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Furthermore</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Lynch</td>\n",
       "      <td>278.41261</td>\n",
       "      <td>paid</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>589</td>\n",
       "      <td>We Need To Talk (She And I Album Version)</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kid Cudi / MGMT / Ratatat</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>Lynch</td>\n",
       "      <td>295.67955</td>\n",
       "      <td>paid</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>589</td>\n",
       "      <td>Pursuit Of Happiness (nightmare)</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Crosby_ Stills &amp; Nash</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>F</td>\n",
       "      <td>7</td>\n",
       "      <td>Lynch</td>\n",
       "      <td>186.90567</td>\n",
       "      <td>paid</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>589</td>\n",
       "      <td>Haven't We Lost Enough?  (LP Version)</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Passion Pit</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>Lynch</td>\n",
       "      <td>174.75873</td>\n",
       "      <td>paid</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>589</td>\n",
       "      <td>Sleepyhead</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    artist   firstName gender  itemInSession  \\\n",
       "0                          Rokia TraorÃƒÂƒÃ‚Â©     Stefany      F              0   \n",
       "1                                   Camila      Tucker      M              1   \n",
       "2                              Carl Thomas      Tucker      M              0   \n",
       "3                                 N.E.R.D.       James      M              0   \n",
       "4  Lil Jon / The East Side Boyz / DJ Flexx  Jacqueline      F              3   \n",
       "5                                     Enya  Jacqueline      F              4   \n",
       "6                              Furthermore  Jacqueline      F              5   \n",
       "7                Kid Cudi / MGMT / Ratatat  Jacqueline      F              6   \n",
       "8                    Crosby_ Stills & Nash  Jacqueline      F              7   \n",
       "9                              Passion Pit  Jacqueline      F              8   \n",
       "\n",
       "   lastName     length level                           location  sessionId  \\\n",
       "0     White  274.88608  free                        Lubbock, TX        693   \n",
       "1  Garrison  230.81751  free   Oxnard-Thousand Oaks-Ventura, CA        555   \n",
       "2  Garrison  196.67546  free   Oxnard-Thousand Oaks-Ventura, CA        698   \n",
       "3    Martin  242.99057  free    Dallas-Fort Worth-Arlington, TX         78   \n",
       "4     Lynch  285.30893  paid  Atlanta-Sandy Springs-Roswell, GA        589   \n",
       "5     Lynch  175.85587  paid  Atlanta-Sandy Springs-Roswell, GA        589   \n",
       "6     Lynch  278.41261  paid  Atlanta-Sandy Springs-Roswell, GA        589   \n",
       "7     Lynch  295.67955  paid  Atlanta-Sandy Springs-Roswell, GA        589   \n",
       "8     Lynch  186.90567  paid  Atlanta-Sandy Springs-Roswell, GA        589   \n",
       "9     Lynch  174.75873  paid  Atlanta-Sandy Springs-Roswell, GA        589   \n",
       "\n",
       "                                        song  userId  \n",
       "0                                        Zen      83  \n",
       "1               Abrazame  (Version Acustica)      40  \n",
       "2            You Ain't Right (Album Version)      40  \n",
       "3                Provider (Remix Radio Edit)      79  \n",
       "4                            Aww Skeet Skeet      29  \n",
       "5                      The Sun In The Stream      29  \n",
       "6  We Need To Talk (She And I Album Version)      29  \n",
       "7           Pursuit Of Happiness (nightmare)      29  \n",
       "8      Haven't We Lost Enough?  (LP Version)      29  \n",
       "9                                 Sleepyhead      29  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('event_datafile_new.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6820 entries, 0 to 6819\n",
      "Data columns (total 11 columns):\n",
      "artist           6820 non-null object\n",
      "firstName        6820 non-null object\n",
      "gender           6820 non-null object\n",
      "itemInSession    6820 non-null int64\n",
      "lastName         6820 non-null object\n",
      "length           6820 non-null float64\n",
      "level            6820 non-null object\n",
      "location         6820 non-null object\n",
      "sessionId        6820 non-null int64\n",
      "song             6820 non-null object\n",
      "userId           6820 non-null int64\n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 586.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‰ None of the columns have NaN values; no issues with the datatype.\n",
    "\n",
    "ðŸ‘‰ For the subsequent data modeling process, the following data type conversions are needed:\n",
    "* convert 'length' to a float,\n",
    "* change 'itemInSession', 'sessionId', and 'userId' to integers,\n",
    "* ensure all other columns are set as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist           3148\n",
       "firstName          84\n",
       "gender              2\n",
       "itemInSession     123\n",
       "lastName           86\n",
       "length           3994\n",
       "level               2\n",
       "location           63\n",
       "sessionId         776\n",
       "song             5190\n",
       "userId             96\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‰ None of the columns contain only unique values, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a connection to Apache Cassandra and create a Sparkify database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1']) # '127.0.0.1' if you have a locally installed Apache Cassandra instance \n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS sparkifydb\n",
    "    WITH REPLICATION = \n",
    "    {'class': 'SimpleStrategy', 'replication_factor': 1}\"\"\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkifydb')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the database tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: Give me the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4.\n",
    "* Table 1: session_history\n",
    "* Primary key (composite): `session_id` and `item_in_session`. In the query, we will use the WHERE statement to filter data based on certain fields. Additionally, grouping by this combination of fields will ensure that each row is unique.\n",
    "* Other columns needed: `artist_name`, `song_title`, `song_length`.\n",
    "\n",
    "#### Question 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182.\n",
    "* Table 2: user_history\n",
    "* Primary key (composite):`user_id`, `session_id`, `item_in_session`.\n",
    "    * In the query, we will use the WHERE statement to filter data based on the `user_id` and `session_id` fields. Additionally, grouping by this combination of fields will ensure that each row is unique. Thus, these columns are needed to be used as *partition keys*. \n",
    "    * `item_in_session` is needed as a *clustering* column. You can not try to access a column or a clustering column if you have not used the other defined clustering column. That's why it needs to be included into the Primary key.\n",
    "    * Since `item_in_session` is not a partition key, it's just a clustering column, we need to denote a compound partition key by enclosing `user_id` and `session_id` in parenthasis\n",
    "* Other columns needed: `artist_name`, `song_title`, `first_name`, `last_name`.\n",
    "\n",
    "#### Question 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "* Table 3: songs_users_history\n",
    "* Primary key (composite): `song_title` and `user_id`. This gives us a unique combination of all the songs listend by every user. In the query, we will use the WHERE statement to filter data based on these fields. \n",
    "* Other columns needed: `first_name`, `last_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tables, insert the data and read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1: session_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS session_history\"\n",
    "query = query + \"(session_id int, item_in_session int, artist_name text, song_title text, song_length double, \\\n",
    "                    PRIMARY KEY (session_id, item_in_session))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert the data into the table\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## Assign the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO session_history (session_id, item_in_session, artist_name, song_title, song_length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        ## Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (int(line[8]), int(line[3]), str(line[0]), str(line[9]), float(line[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_id  item_in_session artist_name song_title                        song_length\n",
      "338         4                Faithless   Music Matters (Mark Knight Dub)  495.3073\n"
     ]
    }
   ],
   "source": [
    "# Select the data from the table to verify that the data model works correctly\n",
    "\n",
    "# Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \n",
    "## sessionId = 338, and itemInSession = 4\n",
    "query = \"SELECT * FROM session_history WHERE session_id=338 AND item_in_session=4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    # Convert rows to a list\n",
    "    data = list(map(lambda row: [row.session_id, row.item_in_session, row.artist_name, row.song_title, row.song_length], rows))\n",
    "\n",
    "# Create a dataframe with column names\n",
    "df1 = pd.DataFrame(data, columns=[\"session_id\", \"item_in_session\", \"artist_name\", \"song_title\", \"song_length\"])\n",
    "\n",
    "print(df1.to_string(index=False, justify='left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2: users_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS users_history\"\n",
    "query = query + \"(user_id int, session_id int, artist_name text, song_title text, \\\n",
    "                    item_in_session int, first_name text, last_name text, \\\n",
    "                    PRIMARY KEY ((user_id, session_id), item_in_session))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data into the table\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "\n",
    "        query = \"INSERT INTO users_history (user_id, session_id, artist_name, song_title, \\\n",
    "                    item_in_session, first_name, last_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        session.execute(query, (int(line[10]), int(line[8]), str(line[0]), str(line[9]), int(line[3]), str(line[1]), str(line[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_name last_name artist_name        song_title                                        \n",
      "Sylvie     Cruz       Down To The Bone                                 Keep On Keepin' On\n",
      "Sylvie     Cruz           Three Drives                                        Greece 2000\n",
      "Sylvie     Cruz      Sebastien Tellier                                          Kilometer\n",
      "Sylvie     Cruz          Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...\n"
     ]
    }
   ],
   "source": [
    "# Select the data from the table to verify that the data model works correctly\n",
    "\n",
    "# Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "query = \"SELECT * FROM users_history WHERE user_id=10 AND session_id=182\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    # Convert rows to a list\n",
    "    data = list(map(lambda row: [row.first_name, row.last_name, row.artist_name, row.song_title], rows))\n",
    "\n",
    "# Create a dataframe with column names\n",
    "df2 = pd.DataFrame(data, columns=[\"first_name\", \"last_name\", \"artist_name\", \"song_title\"])\n",
    "\n",
    "print(df2.to_string(index=False, justify='left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3: songs_users_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS songs_users_history\"\n",
    "query = query + \"(song_title text, user_id int, first_name text, last_name text, \\\n",
    "                    PRIMARY KEY (song_title, user_id))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data into the table\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "\n",
    "        query = \"INSERT INTO songs_users_history (song_title, user_id, first_name, last_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "        \n",
    "        session.execute(query, (str(line[9]), int(line[10]), str(line[1]), str(line[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_name  last_name\n",
      "Jacqueline    Lynch \n",
      "     Tegan   Levine \n",
      "      Sara  Johnson\n"
     ]
    }
   ],
   "source": [
    "# Select the data from the table to verify that the data model works correctly\n",
    "\n",
    "# Query 3: Give me every user name (first and last) in my music app history who listened to the song \n",
    "##'All Hands Against His Own'\n",
    "query = \"SELECT * FROM songs_users_history WHERE song_title='All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    #print(row.first_name, row.last_name)\n",
    "    # Convert rows to a list\n",
    "    data = list(map(lambda row: [row.first_name, row.last_name], rows))\n",
    "\n",
    "# Create a dataframe with column names\n",
    "df3 = pd.DataFrame(data, columns=[\"first_name\", \"last_name\"])\n",
    "\n",
    "print(df3.to_string(index=False, justify='left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"DROP TABLE session_history\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "query = \"DROP TABLE users_history\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "query = \"DROP TABLE songs_users_history\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
